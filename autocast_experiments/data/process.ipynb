{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "import copy\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(f'autocast_cc_news_retrieved.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "negated_questions = json.load(open(f'negated_tf_questions.json'))\n",
    "autocast_questions = json.load(open(f'autocast_questions.json'))\n",
    "qid_to_question = {q['id']: q for q in autocast_questions}\n",
    "qid_to_negation = {q['id']: q for q in negated_questions}\n",
    "all_questions = []\n",
    "for q in data:\n",
    "    q['qtype'] = qid_to_question[q['question_id']]['qtype']\n",
    "    if q['question_id'] in qid_to_negation:\n",
    "        negated_q = copy.deepcopy(q)\n",
    "        negated_q['question'] = qid_to_negation[q['question_id']]['negated']\n",
    "        for day in negated_q['targets']:\n",
    "            day['target'] = 1 - float(day['target']) # flip the forecast probabilities\n",
    "        if q['answers'][0] == 'yes':\n",
    "            negated_q['answers'] = ['no']\n",
    "        else:\n",
    "            negated_q['answers'] = ['yes']\n",
    "        all_questions.append(negated_q)\n",
    "        \n",
    "    all_questions.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4387, 1364)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1, c2 = 0,0\n",
    "temp_train_qs, temp_test_qs = [],[]\n",
    "for d in all_questions:\n",
    "    if d['question_expiry'] < '2021-05-11':\n",
    "        c1 += 1\n",
    "        temp_train_qs.append(d)\n",
    "    else:\n",
    "        temp_test_qs.append(d)\n",
    "        c2 += 1\n",
    "c1, c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'temporal_train.json', \"w\", encoding='utf-8') as writer:\n",
    "    writer.write(json.dumps(temp_train_qs, indent=4, ensure_ascii=False) + \"\\n\")\n",
    "with open(f'temporal_test.json', \"w\", encoding='utf-8') as writer:\n",
    "    writer.write(json.dumps(temp_test_qs, indent=4, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'bm25ce'\n",
    "descending = method != 'dpr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = []\n",
    "for question in all_questions:\n",
    "    new_question = copy.deepcopy(question)\n",
    "    del new_question['targets']\n",
    "\n",
    "    all_ctxs = []\n",
    "    all_scores = []\n",
    "    for target in question['targets']:\n",
    "        if target['ctxs']:\n",
    "            all_ctxs.extend(target['ctxs'])\n",
    "            all_scores.extend([float(ctxs['score']) for ctxs in target['ctxs']])\n",
    "    sorted_idx = [x for _, x in sorted(zip(all_scores, range(len(all_scores))), reverse=descending)]\n",
    "    new_question['ctxs'] = [all_ctxs[i] for i in sorted_idx][:15]\n",
    "    \n",
    "    static_data.append(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4387, 1364)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1, c2 = 0,0\n",
    "static_train_qs, static_test_qs = [],[]\n",
    "for d in static_data:\n",
    "    if d['question_expiry'] < '2021-05-11':\n",
    "        c1 += 1\n",
    "        static_train_qs.append(d)\n",
    "    else:\n",
    "        static_test_qs.append(d)\n",
    "        c2 += 1\n",
    "c1, c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'static_train.json', \"w\", encoding='utf-8') as writer:\n",
    "    writer.write(json.dumps(static_train_qs, indent=4, ensure_ascii=False) + \"\\n\")\n",
    "with open(f'static_test.json', \"w\", encoding='utf-8') as writer:\n",
    "    writer.write(json.dumps(static_test_qs, indent=4, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfe34a9389bfb9158f4a57d38254999ecb4846a6b929cd8c17eb23c1b8c530ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
